{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18271111-f849-41d8-9f86-be48b2762e29",
   "metadata": {},
   "source": [
    "# Загрузка модели - LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77ad263-472a-4989-b58b-1156038936c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebc8106-e046-41f0-951a-8cd051435e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../models/model-q4_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = models\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = models\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      "...............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     0.20 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     2.61 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n",
      "Model metadata: {'general.name': 'models', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '0'}\n"
     ]
    }
   ],
   "source": [
    "# cpu\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"../models/model-q4_K.gguf\",\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    "    n_ctx=2048,\n",
    "    max_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32189675-9696-48e4-b383-740116c99222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu\n",
    "n_gpu_layers = -1  # The number of layers to put on the GPU. The rest will be on the CPU. If you don't know how many layers there are, you can use -1 to move all to GPU.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"models/llama-2-7b-chat.Q3_K_M.gguf\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998e2e9-8c78-45b5-afc9-8e1614c8b5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fae57955-eb0a-4724-98bb-f75ef7e3c0f4",
   "metadata": {},
   "source": [
    "# Загрузка и чтение документа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae24ce-d230-47ff-913b-1c2cf5b3ed6d",
   "metadata": {},
   "source": [
    "## PyPDFium2Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102c257a-f19d-46f2-bd0b-5b77a1c15056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fea5b4d-6357-4fac-b02b-5bee6c7b3dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFium2Loader('../АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ.pdf')\n",
    "data = loader.load()\n",
    "for index, _ in enumerate(data):\n",
    "    data[index].page_content = data[index].page_content.replace('￾', '').replace('\u0004', '-')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265adc31-5763-42c6-b4b9-cdeda5debfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "Технические газы, № 5, 2010\n",
      "ã И.К. Буткевич\n",
      "УДК 621.59(075.8)\n",
      "И.К. Буткевич\n",
      "Институт физических проблем им. П.Л. Капицы РАН, ул. Косыгина, 2, г. Москва, РФ, 117334\n",
      "e-mail: butkevich@kapitza.ras.ru\n",
      "АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ:\n",
      "ПРОБЛЕМЫ И ПУТИ РЕШЕНИЯ\n",
      "Автоматизация современных криогенных гелиевых установок (КГУ) и систем (КГС)\n",
      "является необходимым условием повышения их эффективности и надёжности. Все\n",
      "коммерческие КГУ ведущих фирм снабжаются системами автоматического управления (САУ). Рассматриваются основные концептуальные положения и различные\n",
      "уровни автоматизации на основе отечественных САУ КГУ с поршневыми и турбодетандерами. САУ этого типа предоставляют широкие возможности оператору\n",
      "участвовать как в процессе пусконаладки системы, так и в её перенастройке в\n",
      "процессе эксплуатации. Для дальнейшего совершенствования САУ КГУ и КГС обосновывается создание адаптивных систем автоматизации и диагностических программ, предназначенных для предотвращения аварийных ситуаций и распознавания\n",
      "причин аварий с высокой степенью достоверности.\n",
      "Ключевые слова: Гелий. Криогеника. Ожижение гелия. Криогенная гелиевая установка. Автоматизация. Алгоритм. Система автоматического управления. Оптимизация. Надёжность.\n",
      "I.K. Butkevich\n",
      "AUTOMATIZATION OF CRYOGENIC HELIUM PLANTS AND SYSTEMS:\n",
      "PROBLEMS AND SOLUTIONS\n",
      "Automatization of modern cryogenic helium plants (CHP) and systems (CHS) is a necessary\n",
      "condition for their efficiency and safety increase. All commercial CHP of leading companies are\n",
      "provided with the systems of automatic control (SAC). Basic, conceptual positions and different levels of automatization on the base of domestic SAC CHP with piston and turbo expanders. SAC of this type provide the operator with ample opportunity to participate both in the\n",
      "process of the system commissioning and in its reconfiguration during the work. The creation\n",
      "of automatization adaptive systems and diagnostic programs for handling emergency situations and the identification of accident causes at the highest level of confidence is grounded\n",
      "for further SAC CHP and CHS development.\n",
      "Keywords: Helium. Cryogenics. Helium liquefaction. Cryogenic helium plant. Automatization. Algorithm. System of automatic control. Optimization. Safety.\n",
      "1. ВВЕДЕНИЕ\n",
      "Современные криогенные гелиевые системы\n",
      "(КГС) и установки (КГУ) невозможно представить\n",
      "без автоматизации того или иного уровня. Это связано, с одной стороны, со сложностью протекающих в\n",
      "них теплогидравлических процессов и, с другой стороны, с дефицитом высококвалифицированного персонала. Оба этих фактора обусловливают практическую\n",
      "невозможность без автоматизации обеспечения оптимальной реализации процессов (с минимальными затратами энергии), исключения постоянной опасности\n",
      "влияния человеческого фактора на надёжность систем (установок) и их безопасную эксплуатацию.\n",
      "В настоящей статье излагается видение уровней и\n",
      "проблем автоматизации КГС (КГУ) с точки зрения\n",
      "технолога-криогенщика, не затрагивающего теорию\n",
      "систем автоматического регулирования технологиче-\n",
      "ских процессов, которой посвящено достаточное количество специальной литературы. При этом приходилось учитывать, что криогенная система как объект\n",
      "регулирования обладает всеми свойствами, присущими термомеханическим системам.\n",
      "В общем случае в состав КГУ входят: криогенный\n",
      "блок с детандерами, газгольдер, технологический\n",
      "компрессор, гелиевый ресивер, закачной компрессор,\n",
      "система маслоочистки (может иногда отсутствовать),\n",
      "сосуд Дьюара для жидкого азота (может отсутствовать), блоки осушки и криогенной очистки гелия.\n",
      "КГУ как объект управления обладает рядом специфических особенностей. Основные из них: наличие\n",
      "значительного количества последовательно и парал-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74d5bd-1acd-4e76-ae95-3ae8e2af105d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7580c5d-a0ad-4ae4-9e13-05546eee96c2",
   "metadata": {},
   "source": [
    "# Загурзка эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262a1ae9-aae2-4e68-ab55-8cd84bec10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7da87d-5a6d-42b8-a75f-4d04274930e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_hf_default = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512a14d4-e15a-4444-b647-01d5d1125e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ../DeepPavlov-rubert-base-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at ../DeepPavlov-rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "embeddings_hf_custom = HuggingFaceEmbeddings(model_name=\"../DeepPavlov-rubert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2f9c7-60ad-4c88-8d9c-26c718a8a591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99307443-db3f-4eef-88b7-3f8c5212f359",
   "metadata": {},
   "source": [
    "# Загружаем в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23f4577-7948-423a-8683-6cd5a02cc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cdd051e-f5b5-44de-ab1f-d113617f1269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=400, \n",
    "                                      chunk_overlap=0, \n",
    "                                      separator='\\n',\n",
    "                                      length_function=len,\n",
    "                                      is_separator_regex=False,\n",
    "                                     )\n",
    "docs = text_splitter.split_documents(data)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201cce7b-cf61-4f8e-9788-6262725d021c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "Технические газы, № 5, 2010\n",
      "ã И.К. Буткевич\n",
      "УДК 621.59(075.8)\n",
      "И.К. Буткевич\n",
      "Институт физических проблем им. П.Л. Капицы РАН, ул. Косыгина, 2, г. Москва, РФ, 117334\n",
      "e-mail: butkevich@kapitza.ras.ru\n",
      "АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ:\n",
      "ПРОБЛЕМЫ И ПУТИ РЕШЕНИЯ\n",
      "Автоматизация современных криогенных гелиевых установок (КГУ) и систем (КГС)\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cbb0e5e-5bb6-4909-b607-aa43f9be95fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 54s\n",
      "Wall time: 8min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = FAISS.from_documents(docs, embeddings_hf_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a87939-6627-4c6f-831a-9a1db6abb23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3346985f-8aea-4d89-8487-7d796797007d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"уровень регулирования позволяет автоматически\"\n",
    "docs_res = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5582d58-4a66-4d5c-9f9d-b1d13e3abc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пуск и остановку установки в любое время без специальных предварительных операций, отслеживать изменения параметров, хранить и распечатывать данные, производить аварийное оповещение и осуществлять мониторинг с помощью удалённого доступа.\n",
      "Основной недостаток этих САУ — достаточно жёсткое отношение к пользователю, существенно ограничивающее его возможности влиять на технологический процесс.\n"
     ]
    }
   ],
   "source": [
    "print(docs_res[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fca7c-8684-4307-870c-881d32d3a1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca5139-71f0-49b7-9bc2-3c870b875759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "052646dc-5dcb-4583-a857-0511a61b721c",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb58fb44-7ae7-4f3e-9d4f-1a28cec7fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69f12890-a6dd-49d2-beb8-e1aa5b8c23c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000189BCE5AF10>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2b21b7-9ff5-497f-9890-a2c4802f4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"[INST] <<SYS>>\n",
    "Ты ассистент, который анализирует информацию, представленную в  контексте: {context} и отвечает на вопрос: {question}.\n",
    "Ответ ты даешь на русском языке.\n",
    "<</SYS>>\n",
    "\n",
    "Ответьте на вопрос, основываясь только на следующем контексте:{context}\n",
    "Вопрос: {question}[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5081b82-4622-4fd1-8f74-8aaad290a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_1 = \"\"\"Используйте следующий контекст, чтобы ответить на вопрос в конце. \n",
    "Если вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумать ответ.\n",
    "\n",
    "Контекст: {context}\n",
    "Вопрос: {question}\n",
    "\n",
    "Ответ:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96e44ebb-4f18-4978-ac39-d53c6fa74c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='[INST] <<SYS>>\\nТы ассистент, который анализирует информацию, представленную в  контексте: {context} и отвечает на вопрос: {question}.\\nОтвет ты даешь на русском языке.\\n<</SYS>>\\n\\nОтветьте на вопрос, основываясь только на следующем контексте:{context}\\nВопрос: {question}[/INST]\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1777360-c874-4d02-b839-f997e70b4328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template='[INST] <<SYS>>\\nТы ассистент, который анализирует информацию, представленную в  контексте: {context} и отвечает на вопрос: {question}.\\nОтвет ты даешь на русском языке.\\n<</SYS>>\\n\\nОтветьте на вопрос, основываясь только на следующем контексте:{context}\\nВопрос: {question}[/INST]\\n'), llm=LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001887BD4EAF0>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab0c7c5-8d7f-408f-a4e8-4eafb85b6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Совместно с какой организацией ИФП РАН разработанли и реализовали САУ ожижителя гелия Г-4 с поршневыми детандерами?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a69b6-7869-4857-92ec-eb908e6a7757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b00aadc9-fba1-4111-93fd-60a8427f456b",
   "metadata": {},
   "source": [
    "## способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "041b84e4-d916-4e58-989b-806f5029a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001887BD4EAF0>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d949314-d970-443c-ac39-67894a1ca475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000189BCE5AF10>),\n",
       "  question: RunnableLambda(lambda x: RunnablePassthrough())\n",
       "}\n",
       "| PromptTemplate(input_variables=['context', 'question'], template='[INST] <<SYS>>\\nТы ассистент, который анализирует информацию, представленную в  контексте: {context} и отвечает на вопрос: {question}.\\nОтвет ты даешь на русском языке.\\n<</SYS>>\\n\\nОтветьте на вопрос, основываясь только на следующем контексте:{context}\\nВопрос: {question}[/INST]\\n')\n",
       "| LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001887BD4EAF0>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": lambda x: RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34a2489d-65f2-4e03-a640-508f42079b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   12958.09 ms\n",
      "llama_print_timings:      sample time =     319.17 ms /    33 runs   (    9.67 ms per token,   103.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  498484.95 ms /  2003 tokens (  248.87 ms per token,     4.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13655.80 ms /    32 runs   (  426.74 ms per token,     2.34 tokens per second)\n",
      "llama_print_timings:       total time =  547520.05 ms /  2035 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31min 16s\n",
      "Wall time: 10min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_1 = chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db2f7b7f-a287-4b3e-a7d1-904e04c89970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Совместно с какой организацией ИФП РАН разработанли и реализовали САУ ожижителя гелия Г-4 с поршневыми детандерами?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3f84285-907c-41b0-80f9-37f7fe3c0edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Какая установка на основе гелия была создана на базе установки КГУ-150/4,5?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5983e23-d8f6-4f14-a655-e7624bb2bc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5783641b-7d99-468d-a3e1-b2605752d36b",
   "metadata": {},
   "source": [
    "## способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96ff18f3-e12a-41cf-90c7-dd4e333b7bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000189BCE5AF10>),\n",
       "  question: RunnableLambda(lambda x: RunnablePassthrough())\n",
       "}\n",
       "| LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template='[INST] <<SYS>>\\nТы ассистент, который анализирует информацию, представленную в  контексте: {context} и отвечает на вопрос: {question}.\\nОтвет ты даешь на русском языке.\\n<</SYS>>\\n\\nОтветьте на вопрос, основываясь только на следующем контексте:{context}\\nВопрос: {question}[/INST]\\n'), llm=LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001887BD4EAF0>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": lambda x: RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baf9b9ea-e9c4-4303-bf9b-5cf654fcd3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   12958.09 ms\n",
      "llama_print_timings:      sample time =      58.55 ms /    29 runs   (    2.02 ms per token,   495.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   26423.74 ms /    29 runs   (  911.16 ms per token,     1.10 tokens per second)\n",
      "llama_print_timings:       total time =   30721.28 ms /    30 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 24s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_2 = chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffc5c55f-ab53-4c77-8ead-2fd39c762d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Совместно с какой организацией ИФП РАН разработанли и реализовали САУ ожижителя гелия Г-4 с поршневыми детандерами?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "982b5888-7667-4a19-8cd0-a37e10c44b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='В ИФП РАН совместно с Санкт-Петербургской\\r\\nфирмой «Вертикаль» разработана и реализована САУ\\r\\nожижителя гелия Г-4 с поршневыми детандерами, являющегося прототипом промышленной установки\\r\\nКГУ-150/4,5 [1]. Сейчас совместно с ОАО «НПО Гелиймаш» с учётом имеющегося опыта создаётся автоматизированный турбодетандерный ожижитель гелия\\r\\nОГ-100.', metadata={'source': '../АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ.pdf', 'page': 4}),\n",
       "  Document(page_content='режима, локализуя некие случайные или закономерные, например, слив жидкого гелия из сборника криогенного блока в сосуды Дьюара, возмущения. Впервые на отечественных КГС такая стабилизация параметров была осуществлена на установке КГУ-150/4,5\\r\\nв составе стендовой КГС СПК-100 в лаборатории\\r\\nВНИИКриогенмаша. Позже эти контуры были реализованы на мини-ЭВМ СМ-2. Наиболее полно уровень', metadata={'source': '../АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ.pdf', 'page': 1}),\n",
       "  Document(page_content='регулирования обладает всеми свойствами, присущими термомеханическим системам.\\r\\nВ общем случае в состав КГУ входят: криогенный\\r\\nблок с детандерами, газгольдер, технологический\\r\\nкомпрессор, гелиевый ресивер, закачной компрессор,\\r\\nсистема маслоочистки (может иногда отсутствовать),\\r\\nсосуд Дьюара для жидкого азота (может отсутствовать), блоки осушки и криогенной очистки гелия.', metadata={'source': '../АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ.pdf', 'page': 0}),\n",
       "  Document(page_content='прямого потока гелия между гелиевым и азотным теплообменниками (степенью открытия РВ1).\\r\\nВ турбодетандерных КГУ добавляются аналоговые контуры поддержания рабочей частоты вращения\\r\\nвала детандера регулированием величины тормозной\\r\\nмощности, а в КГУ с турбодетандерами с комбинированными опорами — дискретные или аналоговые\\r\\nконтуры поддержания заданных параметров масла\\r\\n(давления и температуры).', metadata={'source': '../АВТОМАТИЗАЦИЯ КРИОГЕННЫХ ГЕЛИЕВЫХ УСТАНОВОК И СИСТЕМ.pdf', 'page': 3})],\n",
       " 'question': RunnablePassthrough(),\n",
       " 'text': 'Что является прототипом промышленной установки КГУ-150/4,5?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb692ec-d4a1-4b38-8058-7bed5948f4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "805f7176-ec3b-4abd-9090-868740865da4",
   "metadata": {},
   "source": [
    "## способ 3 - RetrievalQA\n",
    "**работает хорошо**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a2eb55e-f851-4459-afdf-4a654a41c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# https://python.langchain.com/docs/modules/chains/#legacy-chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc6396e1-d06e-4036-8c32-c32c2b2324b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001887BD4EAF0>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048)), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x00000189BCE5AF10>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "llm=llm,\n",
    "chain_type='stuff',\n",
    "retriever=retriever\n",
    ")\n",
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e6467e3-4727-4180-89a1-9a2140b956eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   12958.09 ms\n",
      "llama_print_timings:      sample time =     239.09 ms /    11 runs   (   21.73 ms per token,    46.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  210027.98 ms /   758 tokens (  277.08 ms per token,     3.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6131.10 ms /    10 runs   (  613.11 ms per token,     1.63 tokens per second)\n",
      "llama_print_timings:       total time =  252005.99 ms /   768 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 30s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = question\n",
    "\n",
    "res_3 = qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acc95bf9-bd4a-4418-869f-aae5b6c09663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Совместно с какой организацией ИФП РАН разработанли и реализовали САУ ожижителя гелия Г-4 с поршневыми детандерами?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ad6926b-e863-425d-bfe7-b207c4242cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ОАО «Вертикаль»'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c9f68-4d6a-4503-a031-d3e38c19644e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d298255b-1cbe-44df-b6ca-bc1032187305",
   "metadata": {},
   "source": [
    "## ответ без RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1cf08a-45d3-4ad1-b5b4-686ee353ae61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='[INST] <<SYS>>\\nОтветьте на вопрос.\\nЕсли вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумать ответ.\\nВопрос: {question}[/INST]\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"[INST] <<SYS>>\n",
    "Ответьте на вопрос.\n",
    "Если вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумать ответ.\n",
    "Вопрос: {question}[/INST]\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ff7794-9940-47ea-b431-871d8d4d9184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['question'], template='[INST] <<SYS>>\\nОтветьте на вопрос.\\nЕсли вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумать ответ.\\nВопрос: {question}[/INST]\\n'), llm=LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001734429AD60>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1887be85-f331-48ab-9318-62a0f847bca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    9845.30 ms\n",
      "llama_print_timings:      sample time =     258.20 ms /   106 runs   (    2.44 ms per token,   410.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57992.78 ms /   117 tokens (  495.66 ms per token,     2.02 tokens per second)\n",
      "llama_print_timings:        eval time =   37724.01 ms /   105 runs   (  359.28 ms per token,     2.78 tokens per second)\n",
      "llama_print_timings:       total time =  105213.50 ms /   222 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 5s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_variables_dict = {'question': question}\n",
    "result = llm_chain.run(input_variables_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004f6cac-9f13-4fca-b5bf-44208c9505c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Уральский филиал Института физико-химического инженерного обеспечения (ИФП) РАН совместно с ОАО Уральская электрометаллургическая компания (УЭМК) разработали и реализовали солнечно-активные устройства охлаждения ожижителя гелия Г-4 с поршневыми детандерами.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52a488-7db5-4975-a442-904bfcc0c5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe5551b-868d-4483-bdfd-fd83481569e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='[INST] <<SYS>>\\nОтветьте на вопрос.\\nЕсли вы не знаете ответа, просто скажите, что не знаете, не пытайтесь придумать ответ.\\nВопрос: {question}[/INST]\\n')\n",
       "| LlamaCpp(client=<llama_cpp.llama.Llama object at 0x000001734429AD60>, model_path='../models/model-q4_K.gguf', n_ctx=2048, max_tokens=2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = prompt | llm\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b36f566-2d16-464a-b795-47a935e3df21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    9845.30 ms\n",
      "llama_print_timings:      sample time =      41.51 ms /    65 runs   (    0.64 ms per token,  1565.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   27928.65 ms /    65 runs   (  429.67 ms per token,     2.33 tokens per second)\n",
      "llama_print_timings:       total time =   31706.79 ms /    66 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 49s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = llm_chain.invoke(input_variables_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9d7555-6151-4daa-806f-c3baaf18e0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ответ: ИФП РАН совместно с ОАО \"Кратковский завод металлоизделий\" разработали и реализовали САУ ожижителя гелия G-4 с поршневыми детандерами.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfcf01-8dd4-46e1-b113-2c7ec99b2dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407b594-e862-4405-981d-6f5255755126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
